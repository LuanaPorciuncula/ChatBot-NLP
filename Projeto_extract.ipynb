{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto-extract.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hxg5F6gnsUQ0",
        "outputId": "4061466c-db5d-4e28-fe65-aef9714a5cc1"
      },
      "source": [
        "from urllib.request import urlopen\n",
        "import ssl\n",
        "import json\n",
        "\n",
        "ctx = ssl.create_default_context()\n",
        "ctx.check_hostname = False\n",
        "ctx.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "dataTrain = urlopen(\"https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_001.json\", context=ctx).read().decode()\n",
        "dataTest = urlopen(\"https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/test/dialogues_001.json\", context=ctx).read().decode()\n",
        "\n",
        "myJsonTrain = json.loads(dataTrain)\n",
        "myJsonTest = json.loads(dataTest)\n",
        "print (json.dumps(myJsonTrain[0], indent=1)[0:100])\n",
        "print (json.dumps(myJsonTest[0], indent=1)[0:100])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            " \"dialogue_id\": \"PMUL4398.json\",\n",
            " \"services\": [\n",
            "  \"restaurant\",\n",
            "  \"hotel\"\n",
            " ],\n",
            " \"turns\": [\n",
            "  {\n",
            "   \"\n",
            "{\n",
            " \"dialogue_id\": \"MUL0484.json\",\n",
            " \"services\": [\n",
            "  \"attraction\",\n",
            "  \"train\"\n",
            " ],\n",
            " \"turns\": [\n",
            "  {\n",
            "   \"f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcXfKcxq6h3s",
        "outputId": "505f551b-40f0-4156-e358-300622476684"
      },
      "source": [
        "#http://alexminnaar.com/2019/08/22/ner-rnns-tensorflow.html\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuAhXdtyApXj"
      },
      "source": [
        "import re\n",
        "\n",
        "from nltk.util import ngrams\n",
        "\n",
        "timepat = re.compile(\"\\d{1,2}[:]\\d{1,2}\")\n",
        "pricepat = re.compile(\"\\d{1,3}[.]\\d{1,2}\")\n",
        "\n",
        "fin = urlopen(\"https://raw.githubusercontent.com/budzianowski/multiwoz/master/utils/mapping.pair\", context=ctx)\n",
        "replacements = []\n",
        "for line in fin.readlines():\n",
        "    line = line.decode().replace('\\n', '')\n",
        "    tok_from, tok_to = line.replace('\\n', '').split('\\t')\n",
        "    replacements.append((' ' + tok_from + ' ', ' ' + tok_to + ' '))\n",
        "\n",
        "\n",
        "def insertSpace(token, text):\n",
        "    sidx = 0\n",
        "    while True:\n",
        "        sidx = text.find(token, sidx)\n",
        "        if sidx == -1:\n",
        "            break\n",
        "        if sidx + 1 < len(text) and re.match('[0-9]', text[sidx - 1]) and \\\n",
        "                re.match('[0-9]', text[sidx + 1]):\n",
        "            sidx += 1\n",
        "            continue\n",
        "        if text[sidx - 1] != ' ':\n",
        "            text = text[:sidx] + ' ' + text[sidx:]\n",
        "            sidx += 1\n",
        "        if sidx + len(token) < len(text) and text[sidx + len(token)] != ' ':\n",
        "            text = text[:sidx + 1] + ' ' + text[sidx + 1:]\n",
        "        sidx += 1\n",
        "    return text\n",
        "\n",
        "\n",
        "def normalize(text):\n",
        "    # lower case every word\n",
        "    text = text.lower()\n",
        "\n",
        "    # replace white spaces in front and end\n",
        "    text = re.sub(r'^\\s*|\\s*$', '', text)\n",
        "\n",
        "    # hotel domain pfb30\n",
        "    text = re.sub(r\"b&b\", \"bed and breakfast\", text)\n",
        "    text = re.sub(r\"b and b\", \"bed and breakfast\", text)\n",
        "\n",
        "    # normalize phone number\n",
        "    ms = re.findall('\\(?(\\d{3})\\)?[-.\\s]?(\\d{3})[-.\\s]?(\\d{4,5})', text)\n",
        "    if ms:\n",
        "        sidx = 0\n",
        "        for m in ms:\n",
        "            sidx = text.find(m[0], sidx)\n",
        "            if text[sidx - 1] == '(':\n",
        "                sidx -= 1\n",
        "            eidx = text.find(m[-1], sidx) + len(m[-1])\n",
        "            text = text.replace(text[sidx:eidx], ''.join(m))\n",
        "\n",
        "    # normalize postcode\n",
        "    ms = re.findall('([a-z]{1}[\\. ]?[a-z]{1}[\\. ]?\\d{1,2}[, ]+\\d{1}[\\. ]?[a-z]{1}[\\. ]?[a-z]{1}|[a-z]{2}\\d{2}[a-z]{2})',\n",
        "                    text)\n",
        "    if ms:\n",
        "        sidx = 0\n",
        "        for m in ms:\n",
        "            sidx = text.find(m, sidx)\n",
        "            eidx = sidx + len(m)\n",
        "            text = text[:sidx] + re.sub('[,\\. ]', '', m) + text[eidx:]\n",
        "\n",
        "    # weird unicode bug\n",
        "    text = re.sub(u\"(\\u2018|\\u2019)\", \"'\", text)\n",
        "\n",
        "    # replace time and and price\n",
        "    times = re.findall(timepat, text)\n",
        "    prices = re.findall(pricepat, text)\n",
        "    text = re.sub(timepat, ' [value_time] ', text)\n",
        "    text = re.sub(pricepat, ' [value_price] ', text)\n",
        "    #text = re.sub(pricepat2, '[value_price]', text)\n",
        "\n",
        "    # replace st.\n",
        "    text = text.replace(';', ',')\n",
        "    text = re.sub('$\\/', '', text)\n",
        "    text = text.replace('/', ' and ')\n",
        "\n",
        "    # replace other special characters\n",
        "    text = text.replace('-', ' ')\n",
        "    text = re.sub('[\\\":\\<>@\\(\\)]', '', text)\n",
        "\n",
        "    # insert white space before and after tokens:\n",
        "    for token in ['?', '.', ',', '!']:\n",
        "        text = insertSpace(token, text)\n",
        "\n",
        "    # insert white space for 's\n",
        "    text = insertSpace('\\'s', text)\n",
        "\n",
        "    # replace it's, does't, you'd ... etc\n",
        "    text = re.sub('^\\'', '', text)\n",
        "    text = re.sub('\\'$', '', text)\n",
        "    text = re.sub('\\'\\s', ' ', text)\n",
        "    text = re.sub('\\s\\'', ' ', text)\n",
        "    for fromx, tox in replacements:\n",
        "        text = ' ' + text + ' '\n",
        "        text = text.replace(fromx, tox)[1:-1]\n",
        "\n",
        "    # remove multiple spaces\n",
        "    text = re.sub(' +', ' ', text)\n",
        "\n",
        "    # concatenate numbers\n",
        "    tmp = text\n",
        "    tokens = text.split()\n",
        "    i = 1\n",
        "    while i < len(tokens):\n",
        "        if re.match(u'^\\d+$', tokens[i]) and \\\n",
        "                re.match(u'\\d+$', tokens[i - 1]):\n",
        "            tokens[i - 1] += tokens[i]\n",
        "            del tokens[i]\n",
        "        else:\n",
        "            i += 1\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    for time in times:\n",
        "      text = re.sub('\\\\[value_time\\\\]', time, text, 1)\n",
        "\n",
        "    for price in prices:\n",
        "      text = re.sub('\\\\[value_price\\\\]', price, text, 1)\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zXUsM586k3E",
        "outputId": "3031cfe4-e121-4416-aefd-ecc936b44afb"
      },
      "source": [
        "# filter\n",
        "import string\n",
        "\n",
        "def filter(data):\n",
        "  result = []\n",
        "\n",
        "  for i, obj in enumerate(data):\n",
        "      turns = obj.get(\"turns\", None)\n",
        "      for turn in turns:\n",
        "          if turn:\n",
        "              utterance = turn.get(\"utterance\", None)\n",
        "              if utterance:\n",
        "                  frames = turn.get(\"frames\", None)\n",
        "                  if frames:\n",
        "                      dic = dict()\n",
        "                      res = [[], []]\n",
        "                      for frame in frames: \n",
        "                          state = frame.get(\"state\", None)\n",
        "                          service = frame.get(\"service\", None)\n",
        "                          if service and service == \"restaurant\" and state:\n",
        "                              slot_values = state.get(\"slot_values\", None)\n",
        "                              if slot_values and len(slot_values) != 0:\n",
        "                                  for key, value in slot_values.items():\n",
        "                                      for elem in value:\n",
        "                                        dic[elem] = key\n",
        "\n",
        "\n",
        "                      text = normalize(utterance)\n",
        "                      for word in text.split(\" \"):\n",
        "                          res[0].append(word)\n",
        "                          res[1].append(dic.get(word, \"other\"))\n",
        "\n",
        "                      result.append(res)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return result\n",
        "\n",
        "train_dataset = filter(myJsonTrain)\n",
        "for i, elem in enumerate(train_dataset):\n",
        "      # print(elem)\n",
        "      if i > 30:\n",
        "        # print(\"--------------------\")\n",
        "        break\n",
        "test_dataset = filter(myJsonTest)\n",
        "for i, elem in enumerate(test_dataset):\n",
        "      # print(elem)\n",
        "      if i > 30:\n",
        "        # print(\"--------------------\")\n",
        "        break\n",
        "\n",
        "\n",
        "test_dataset[6:9]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['can',\n",
              "   'you',\n",
              "   'book',\n",
              "   'me',\n",
              "   'a',\n",
              "   'table',\n",
              "   'for',\n",
              "   '11:00',\n",
              "   'on',\n",
              "   'friday',\n",
              "   '?'],\n",
              "  ['other',\n",
              "   'other',\n",
              "   'other',\n",
              "   'other',\n",
              "   'other',\n",
              "   'other',\n",
              "   'other',\n",
              "   'restaurant-booktime',\n",
              "   'other',\n",
              "   'restaurant-bookday',\n",
              "   'other']],\n",
              " [['actually', ',', 'for', '4', ',', 'please', '.'],\n",
              "  ['other',\n",
              "   'other',\n",
              "   'other',\n",
              "   'restaurant-bookpeople',\n",
              "   'other',\n",
              "   'other',\n",
              "   'other']],\n",
              " [['great',\n",
              "   ',',\n",
              "   'can',\n",
              "   'you',\n",
              "   'also',\n",
              "   'get',\n",
              "   'me',\n",
              "   'information',\n",
              "   'or',\n",
              "   'architecture',\n",
              "   'in',\n",
              "   'the',\n",
              "   'area'],\n",
              "  ['other',\n",
              "   'other',\n",
              "   'other',\n",
              "   'other',\n",
              "   'other',\n",
              "   'other',\n",
              "   'other',\n",
              "   'other',\n",
              "   'other',\n",
              "   'other',\n",
              "   'other',\n",
              "   'other',\n",
              "   'other']]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    }
  ]
}