{
  "affirm": {
    "precision": 1.0,
    "recall": 0.16666666666666666,
    "f1-score": 0.2857142857142857,
    "support": 6,
    "confused_with": {
      "greet": 3,
      "find_res": 1,
      "deny": 1
    }
  },
  "deny": {
    "precision": 0.6,
    "recall": 0.42857142857142855,
    "f1-score": 0.5,
    "support": 7,
    "confused_with": {
      "find_res": 3,
      "greet": 1
    }
  },
  "book_res": {
    "precision": 0.8656716417910447,
    "recall": 0.90625,
    "f1-score": 0.8854961832061069,
    "support": 64,
    "confused_with": {
      "find_res": 6
    }
  },
  "greet": {
    "precision": 0.6842105263157895,
    "recall": 0.8125,
    "f1-score": 0.742857142857143,
    "support": 16,
    "confused_with": {
      "goodbye": 1,
      "find_res": 1
    }
  },
  "find_res": {
    "precision": 0.9970738844184345,
    "recall": 0.9978038067349927,
    "f1-score": 0.9974387120380535,
    "support": 4098,
    "confused_with": {
      "book_res": 9
    }
  },
  "goodbye": {
    "precision": 0.8888888888888888,
    "recall": 0.7272727272727273,
    "f1-score": 0.7999999999999999,
    "support": 11,
    "confused_with": {
      "greet": 2,
      "find_res": 1
    }
  },
  "accuracy": 0.9928605425987624,
  "macro avg": {
    "precision": 0.8393074902356931,
    "recall": 0.6731774382076359,
    "f1-score": 0.7019177206359314,
    "support": 4202
  },
  "weighted avg": {
    "precision": 0.9929407209948123,
    "recall": 0.9928605425987624,
    "f1-score": 0.9924025696471048,
    "support": 4202
  }
}